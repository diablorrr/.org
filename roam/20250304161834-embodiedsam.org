:PROPERTIES:
:ID:       131788ba-3396-44a7-99d7-88a907f50164
:END:
#+title: EmbodiedSAM
#+filetags: paper

* 动机 :ATTACH:
:PROPERTIES:
:ID:       e2559ff4-3e31-4189-8e60-1dfb7a6a33fa
:END:
[[attachment:_20250304_193408screenshot.png]]
** 先前工作的问题
先前的3D语义分割：
1. 使用离线方法：即使用预先收集的数据
2. 推理速度慢
3. 细粒度不够：未将场景中的一切物体进行分割，精确度低
** 对先前工作的改进
1. 在线方法：输入数据是流式[[id:08d89f98-95e1-4f75-8ec3-7f302ff33d15][RGB-D]]视频而非预先收集的数据，视觉感知与数据采集同步进行
2. 实时性：提高推理速度
3. 高度泛化：将场景中的一切物体进行分割，且精确度高


* 模型 :ATTACH:
:PROPERTIES:
:ID:       86c19508-bf63-4a5e-a32d-e3914ed704e1
:END:
[[attachment:_20250304_210041screenshot.png]]
- 目的 :: 实时的对相应的3D场景中的任意实例进行分割
** 查询提升(Query Lifting)
- 目的 :: 将 2D实例掩码 提升为 3D [[id:b319fd25-1f6b-4a8b-b175-892a271ee6f8][Superpoint]]特征Fs
*** 工作流程
- 分支1 ::
  原始输入[[id:08d89f98-95e1-4f75-8ec3-7f302ff33d15][RGB-D]]图 => 根据[[id:d369d83f-0d9c-4b58-a45a-8f286bb5f60a][深度图]]生成点云
  => Temporal-aware 3D U-Net (3D sparse U-Net + 记忆模块)
  => 时间感知的3D特征Fp
- 分支2 ::
  原始输入[[id:08d89f98-95e1-4f75-8ec3-7f302ff33d15][RGB-D]]图 => 根据[[id:5633cfb7-c910-4a90-9005-800fec4cd468][SAM]]生成 2D Mask
  => 以 2D Mask 为 索引S ，将分支1的[[id:eab6111a-7301-4436-acf2-268b0c314298][点云]]聚类成[[id:b319fd25-1f6b-4a8b-b175-892a271ee6f8][Superpoint]]
  => 将索引S与分支1的Fp 加入 [[id:69e48c36-d1d9-42c7-883b-dc94e2c212fa][Geo-aware Pooling]](GP)
  => 生成[[id:b319fd25-1f6b-4a8b-b175-892a271ee6f8][Superpoint]]特征Fs(Fs是整个3D场景的点云特征)

** 查询细化(Query Refinement)
- 目的 :: 细化3D实例查询向量
*** 工作流程
- 流程 ::
  Fs中每次随机选取部分特征作为 3D实例查询Qt
  => Qt和Fs进行 [[id:b319fd25-1f6b-4a8b-b175-892a271ee6f8][Superpoint]] Masked [[id:936da8b9-360e-447d-87db-6debc37c9314][cross-attention]](SMCA) => 捕获场景与实例之间的关系
  => Qt再做[[id:9fa4df48-a4d9-4399-bfa5-043a53fd5855][self-attention]]
  => 再与Fp做 Point Mask Generation(PMG) => 得到更细粒度的3D掩码
  => GP => 得到 Attention Mask => 细化Qt
*** 为什么进行了SMCA和PMG？
因为[[id:b319fd25-1f6b-4a8b-b175-892a271ee6f8][Superpoint]]的细粒度不高，也就是精确度不够高，但计算量小；
时间感知的3D[[id:eab6111a-7301-4436-acf2-268b0c314298][点云]]特征Fp做SMCA精确度高，但计算消耗量大 => 折中

** 查询合并(Query Merging)
- 目的 :: 将上一个时间步的[[id:eab6111a-7301-4436-acf2-268b0c314298][点云]]分割与当前时间步的合并 => 增量的方式获得[[id:eab6111a-7301-4436-acf2-268b0c314298][点云]]分割
*** 工作流程
- 流程 ::
  查询细化得到的 Mcur 为当前[[id:eab6111a-7301-4436-acf2-268b0c314298][点云]]分割，Mpre为先前的[[id:eab6111a-7301-4436-acf2-268b0c314298][点云]]分割，合并向量
  => 得到当前时间步的分割
  => 并将其作为上一个时间步的分割


* 实验

** 评估指标
- 平均精度(AP) ::
  1. 是衡量模型在不同交并比(IoU)阈值下检测和分割实例能力的指标
  2. AP越高，模型在各种交并比下的性能越稳定和准确
- AP50和AP25 ::
  1. 分别表示在IoU阈值为0.5和0.25时的平均精度
  2. 这些指标用于评估模型在不同精度要求下的性能
- 速度(ms per frame) ::
  1. 衡量模型处理每帧数据所需的时间，反映了模型的实时性

** 数据集
- ScanNet :: 该数据集提供了丰富的室内场景数据，适用于评估模型在一般场景下的性能
- ScanNet200 :: 在ScanNet的基础上提供了更细粒度的标注。这个数据集更具挑战性，能够评估模型在处理复杂场景和多类别实例时的能力
- SceneNN :: 包含50个高质量扫描场景，带有实例和语义标签。用于验证模型的泛化能力和在高质量数据上的性能
- 3RScan :: 室内数据集，其RGB-D序列是通过快速移动的摄像头采集的。这个数据集用于评估模型在处理快速移动和模糊数据时的鲁棒性和泛化能力

** 对比实验
** 消融实验
